
##SE-POPO: Avoiding $\exp(R_{max})$ scaling in RLHF through Preference-based Exploration
